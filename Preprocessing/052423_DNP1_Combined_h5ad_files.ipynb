{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPxDHOgMXyzZkW1aDRq3qAH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DPariser/DataScience/blob/main/Preprocessing/052423_DNP1_Combined_h5ad_files.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is  used to time the running of the notebook\n",
        "import time\n",
        "start_time = time.time()"
      ],
      "metadata": {
        "id": "Bodk1zj0dTdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# These packages are pre-installed on Google Colab, but are included here to simplify running this notebook locally\n",
        "%%capture\n",
        "!pip install matplotlib\n",
        "!pip install scikit-learn\n",
        "!pip install numpy\n",
        "!pip install scipy\n",
        "!pip install scanpy\n",
        "!pip install anndata\n",
        "!pip3 install leidenalg"
      ],
      "metadata": {
        "id": "yoBFwzsrdW1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install packages for analysis and plotting\n",
        "from scipy.io import mmread\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import os\n",
        "import scanpy as sc\n",
        "import anndata as ad\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "from scipy.sparse import csr_matrix\n",
        "matplotlib.rcParams.update({'font.size': 22})\n",
        "%config InlineBackend.figure_format = 'retina'"
      ],
      "metadata": {
        "id": "eoe8oZAtdYux"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚ùó**Connect to the Data**\n",
        "\n",
        "The data is stored on a shared location in Google Drive. Since many of the files are very large and thus it is not feasable to download them to a location and use them. One good way of dealing with this situation is to create a shortcut to your own Google Drive and point to the shortcut and use them just like they are your own files on Google Drive. Here is the instruction how to set this up.\n",
        "\n",
        "* Click on the link to the share location of the data.\n",
        "* Nevigate to the \"Data files\" folder.\n",
        "* Click on the \"Dropdown\" arrow right next to the breaksrumb on the top right.\n",
        "* Choose \"Add shortcut to Drive\".\n",
        "\n",
        "Now it should appear in your Google Drive as the \"Data files\" folder.\n",
        "You can now connect to your Google Drive and access the file.\n",
        "From this point on, we assume that you have the Google Drive setup this way.\n",
        "\n",
        "Let's mount the Google Drive:"
      ],
      "metadata": {
        "id": "ycH-WWK8duoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kngSw9sTdoa1",
        "outputId": "05b50c19-fc1e-49ef-9a25-aef3163dad45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Google drive root\n",
        "gd_root = \"/content/drive/MyDrive/Pate_Lab/DNP/Bioinformatics\"\n",
        "\n",
        "# Data roots\n",
        "patient_root = f\"{gd_root}/H17_LungMk/Data_files/HRA001149/HRR339729\"\n",
        "lungmk_root = f\"{gd_root}/H17_LungMk/LungMk\"\n",
        "\n",
        "# Working directories\n",
        "patient_dir = f\"{patient_root}\"\n",
        "lungmk_dir = f\"{lungmk_root}\"\n",
        "\n",
        "# Create the directories if they don't exist\n",
        "!mkdir -p \"{patient_dir}\"\n",
        "!mkdir -p \"{lungmk_dir}\"\n",
        "\n",
        "# List the contents of the directories\n",
        "print(\"Contents of patient directory:\")\n",
        "!ls \"{patient_dir}\"\n",
        "print(\"\\nContents of LungMk directory:\")\n",
        "!ls \"{lungmk_dir}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwhgk-h9d2Xx",
        "outputId": "2f3ad7fb-b7f2-4fe6-c6d1-d95bfe9daba2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of patient directory:\n",
            "10xv2_whitelist.txt\t\t HRR339729_r2.fastq.gz\toutput.bus\n",
            "counts_unfiltered\t\t HRR339729_sta.xml\toutput.unfiltered.bus\n",
            "filtered_normalized_counts.h5ad  inspect.json\t\trun_info.json\n",
            "HRR339729_f1.fastq.gz\t\t matrix.ec\t\ttranscripts.txt\n",
            "\n",
            "Contents of LungMk directory:\n",
            "10xv2_whitelist.txt  inspect.json\t    run_info.json\n",
            "counts_unfiltered    matrix.ec\t\t    t2g.txt\n",
            "GRCh38genome.idx     output.bus\t\t    transcripts.txt\n",
            "index.idx\t     output.unfiltered.bus  v1nm7lpnqz5syh8dyzdk2zs8bglncfib.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code performs an analysis of patient data stored in filtered_normalized_counts.h5ad files within a specific directory. It starts by importing the necessary libraries. The goal is to extract relevant information for each patient, including cell count, UMI count, gene count, and mitochondrial percentage. The code defines a function called get_patient_data that retrieves and organizes the data for each patient. It iterates through the patient IDs, checks if the corresponding file exists, and loads it using anndata. The required metrics are calculated from the loaded data. The patient data is then stored in a DataFrame. The code sorts the DataFrame based on cell count in descending order and prints the sorted data. Finally, the sorted data is saved as a LaTeX file. This code allows for the efficient extraction, analysis, and sorting of patient data, facilitating further investigations or reporting."
      ],
      "metadata": {
        "id": "l26cbmghgsP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify all the patients so we can loop through them in the cell below\n",
        "folder_path = \"/content/drive/MyDrive/Pate_Lab/DNP/Bioinformatics/H17_LungMk/Data_files/HRA001149\"\n",
        "\n",
        "# List the directories in the folder\n",
        "directories = [d for d in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, d))]\n",
        "\n",
        "# Use the directories as patient_ids\n",
        "patient_ids = directories\n",
        "\n",
        "def get_patient_data(patient_ids, folder_path):\n",
        "    # Open the LaTeX file\n",
        "    with open(\"/content/drive/MyDrive/Pate_Lab/DNP/Bioinformatics/H17_LungMk/Combined_Data/patient_data.tex\", \"w\") as f:\n",
        "        # Write the header\n",
        "        f.write(\"\\\\begin{tabular}{lrrrr}\\n\")\n",
        "        f.write(\"\\\\textbf{Patient ID} & \\\\textbf{Cell Count} & \\\\textbf{UMI Count} & \\\\textbf{Gene Count} & \\\\textbf{Mito \\%} \\\\\\\\ \\\\hline\\n\")\n",
        "\n",
        "        for patient_id in patient_ids:\n",
        "            patient_root = f\"{folder_path}/{patient_id}\"\n",
        "            filtered_normalized_counts_file = f\"{patient_root}/filtered_normalized_counts.h5ad\"\n",
        "\n",
        "            # Check if the filtered and normalized counts file exists\n",
        "            if os.path.exists(filtered_normalized_counts_file):\n",
        "                # Load the h5ad file\n",
        "                adata = ad.read_h5ad(filtered_normalized_counts_file)\n",
        "\n",
        "                # Calculate the cell count\n",
        "                cell_count = adata.shape[0]\n",
        "\n",
        "                # Calculate total UMI count\n",
        "                umi_count = adata.X.sum()\n",
        "\n",
        "                # Calculate total gene count\n",
        "                gene_count = adata.shape[1]\n",
        "\n",
        "                # Calculate mito % per patient\n",
        "                mito_genes = adata.var_names.str.startswith('MT-')\n",
        "                mito_percent = np.sum(adata[:, mito_genes].X) / np.sum(adata.X)\n",
        "\n",
        "                # Write the data for this patient to the file\n",
        "                f.write(f\"{patient_id} & {cell_count} & {umi_count} & {gene_count} & {mito_percent:.2f} \\\\\\\\ \\n\")\n",
        "\n",
        "        # Write the footer\n",
        "        f.write(\"\\\\end{tabular}\")\n",
        "\n",
        "# Call the function with your patient_ids and folder_path\n",
        "get_patient_data(patient_ids, folder_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHF24Gl8gU8L",
        "outputId": "3b74ce67-5d51-4b90-dee2-1a44a64e16c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-9bb29f840555>:43: RuntimeWarning: invalid value encountered in true_divide\n",
            "  mito_percent = np.sum(adata[:, mito_genes].X) / np.sum(adata.X)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is a piece of code that will go through all the patients and print the IDs of those with more than 2000 cells"
      ],
      "metadata": {
        "id": "-yKhht3AkgJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify all the patients\n",
        "folder_path = \"/content/drive/MyDrive/Pate_Lab/DNP/Bioinformatics/H17_LungMk/Data_files/HRA001149\"\n",
        "\n",
        "# List the directories in the folder\n",
        "directories = [d for d in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, d))]\n",
        "\n",
        "# Use the directories as patient_ids\n",
        "patient_ids = directories\n",
        "\n",
        "for patient_id in patient_ids:\n",
        "    patient_root = f\"{folder_path}/{patient_id}\"\n",
        "    filtered_normalized_counts_file = f\"{patient_root}/filtered_normalized_counts.h5ad\"\n",
        "\n",
        "    # Check if the filtered and normalized counts file exists\n",
        "    if os.path.exists(filtered_normalized_counts_file):\n",
        "        # Load the h5ad file\n",
        "        adata = ad.read_h5ad(filtered_normalized_counts_file)\n",
        "\n",
        "        # Calculate the cell count\n",
        "        cell_count = adata.shape[0]\n",
        "\n",
        "        # If the cell count is above 2000, print the patient ID\n",
        "        if cell_count > 2000:\n",
        "            print(f\"Patient {patient_id} has {cell_count} cells.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlOnR1vfkhCh",
        "outputId": "633f1aff-475d-4bbe-d009-475219573b15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patient HRR339741 has 4390 cells.\n",
            "Patient HRR339743 has 5175 cells.\n",
            "Patient HRR339748 has 4847 cells.\n",
            "Patient HRR339751 has 6052 cells.\n",
            "Patient HRR339754 has 4922 cells.\n",
            "Patient HRR339757 has 5752 cells.\n",
            "Patient HRR339760 has 5193 cells.\n",
            "Patient HRR339763 has 7206 cells.\n",
            "Patient HRR339787 has 6195 cells.\n",
            "Patient HRR339790 has 5372 cells.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we combine h5ad files from the patients with the most cells. However, due to memory constraints, we will chunk the data. We append the AnnData objects from each h5ad file one by one. It will then save the combined data to a new h5ad file.\n",
        "\n",
        "In this script, each AnnData object is loaded and then concatenated to a main AnnData object, which is then written back to disk after each iteration. This allows us to keep only one AnnData object in memory at a time.\n",
        "\n",
        "Note: Be aware that this operation may take some time depending on the size of your data.\n",
        "\n",
        "*   I tried this method with all top ten of the patients with the highest cell count and it was too much RAM\n",
        "* Originally I had it at >2,000 cells, changed it to >5,300 cells\n",
        "\n"
      ],
      "metadata": {
        "id": "jZPzWu8qlPZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify all the patients\n",
        "folder_path = \"/content/drive/MyDrive/Pate_Lab/DNP/Bioinformatics/H17_LungMk/Data_files/HRA001149\"\n",
        "save_path = \"/content/drive/MyDrive/Pate_Lab/DNP/Bioinformatics/H17_LungMk/Combined_Data/combined_data.h5ad\"\n",
        "\n",
        "# List the directories in the folder\n",
        "directories = [d for d in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, d))]\n",
        "\n",
        "# Use the directories as patient_ids\n",
        "patient_ids = directories\n",
        "\n",
        "# Initialize combined_adata as an empty AnnData object\n",
        "combined_adata = ad.AnnData(X=np.empty((0,0)))\n",
        "\n",
        "for patient_id in patient_ids:\n",
        "    patient_root = f\"{folder_path}/{patient_id}\"\n",
        "    filtered_normalized_counts_file = f\"{patient_root}/filtered_normalized_counts.h5ad\"\n",
        "\n",
        "    # Check if the filtered and normalized counts file exists\n",
        "    if os.path.exists(filtered_normalized_counts_file):\n",
        "        # Load the h5ad file\n",
        "        adata = ad.read_h5ad(filtered_normalized_counts_file)\n",
        "\n",
        "        # Calculate the cell count\n",
        "        cell_count = adata.shape[0]\n",
        "\n",
        "        # If the cell count is above 5300, include the patient data in the combined file\n",
        "        if cell_count > 5300:\n",
        "            print(f\"Adding data for patient {patient_id}...\")\n",
        "            adata.obs['batch'] = patient_id  # Assign batch category for the current patient\n",
        "\n",
        "            if combined_adata.n_obs == 0:\n",
        "                combined_adata = adata\n",
        "            else:\n",
        "                combined_adata = combined_adata.concatenate(adata, index_unique=None, batch_key='batch')\n",
        "\n",
        "# Write the final combined dataset to disk\n",
        "if combined_adata.n_obs > 0:\n",
        "    combined_adata.write(save_path)\n",
        "\n",
        "print(\"Combination of all files finished.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdrRjNgYja_y",
        "outputId": "b96401b0-9b42-4875-b939-060cffc7ab7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding data for patient HRR339751...\n",
            "Adding data for patient HRR339757...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1755: FutureWarning: The AnnData.concatenate method is deprecated in favour of the anndata.concat function. Please use anndata.concat instead.\n",
            "\n",
            "See the tutorial for concat at: https://anndata.readthedocs.io/en/latest/concatenation.html\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1830: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
            "  utils.warn_names_duplicates(\"obs\")\n",
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1830: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
            "  utils.warn_names_duplicates(\"obs\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "It seems that we can only get through HRR339751 and HRR339757, thus we are going to just focus on combining these two"
      ],
      "metadata": {
        "id": "hLtqGDNao_O0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify all the patients\n",
        "folder_path = \"/content/drive/MyDrive/Pate_Lab/DNP/Bioinformatics/H17_LungMk/Data_files/HRA001149\"\n",
        "save_path = \"/content/drive/MyDrive/Pate_Lab/DNP/Bioinformatics/H17_LungMk/Combined_Data/combined_data.h5ad\"\n",
        "\n",
        "# Specify the two patients\n",
        "patient_ids = [\"HRR339751\", \"HRR339757\"]\n",
        "\n",
        "# Initialize combined_adata as an empty AnnData object\n",
        "combined_adata = ad.AnnData(X=np.empty((0,0)))\n",
        "\n",
        "for patient_id in patient_ids:\n",
        "    patient_root = f\"{folder_path}/{patient_id}\"\n",
        "    filtered_normalized_counts_file = f\"{patient_root}/filtered_normalized_counts.h5ad\"\n",
        "\n",
        "    # Check if the filtered and normalized counts file exists\n",
        "    if os.path.exists(filtered_normalized_counts_file):\n",
        "        # Load the h5ad file\n",
        "        adata = ad.read_h5ad(filtered_normalized_counts_file)\n",
        "\n",
        "        print(f\"Adding data for patient {patient_id}...\")\n",
        "        adata.obs['batch'] = patient_id  # Assign batch category for the current patient\n",
        "\n",
        "        if combined_adata.n_obs == 0:\n",
        "            combined_adata = adata\n",
        "        else:\n",
        "            combined_adata = combined_adata.concatenate(adata, index_unique=None, batch_key='batch')\n",
        "\n",
        "# Write the final combined dataset to disk\n",
        "if combined_adata.n_obs > 0:\n",
        "    combined_adata.write(save_path)\n",
        "\n",
        "print(\"Combination of all files finished.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSnmO2KUpHdt",
        "outputId": "f7e1e904-52d9-4454-e552-395379e4c731"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding data for patient HRR339751...\n",
            "Adding data for patient HRR339757...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1755: FutureWarning: The AnnData.concatenate method is deprecated in favour of the anndata.concat function. Please use anndata.concat instead.\n",
            "\n",
            "See the tutorial for concat at: https://anndata.readthedocs.io/en/latest/concatenation.html\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1830: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
            "  utils.warn_names_duplicates(\"obs\")\n",
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1830: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
            "  utils.warn_names_duplicates(\"obs\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combination of all files finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I tried adding more patients to the combined data\n",
        "\n",
        "RAM crashed with these patients\n",
        "*   HRR339763 \n",
        "\n",
        "Patients Added:\n",
        "\n",
        "*   HRR339751\n",
        "*   HRR339757\n",
        "* HRR339741\n",
        "\n",
        "Patient HRR339743 has 5175 cells.\n",
        "Patient HRR339748 has 4847 cells.\n",
        "Patient HRR339754 has 4922 cells.\n",
        "Patient HRR339760 has 5193 cells.\n",
        "Patient HRR339763 has 7206 cells.\n",
        "Patient HRR339787 has 6195 cells.\n",
        "Patient HRR339790 has 5372 cells.\n",
        "\n"
      ],
      "metadata": {
        "id": "XAWdzYw3rBY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths to the files\n",
        "folder_path = \"/content/drive/MyDrive/Pate_Lab/DNP/Bioinformatics/H17_LungMk/Data_files/HRA001149\"\n",
        "save_path = \"/content/drive/MyDrive/Pate_Lab/DNP/Bioinformatics/H17_LungMk/Combined_Data/combined_data.h5ad\"\n",
        "combined_data_path = \"/content/drive/MyDrive/Pate_Lab/DNP/Bioinformatics/H17_LungMk/Combined_Data/combined_data.h5ad\"\n",
        "\n",
        "# Load the combined data\n",
        "combined_adata = ad.read_h5ad(combined_data_path)\n",
        "\n",
        "# Add the new patient\n",
        "new_patient_id = \"HRR339741\"\n",
        "new_patient_root = f\"{folder_path}/{new_patient_id}\"\n",
        "new_patient_file = f\"{new_patient_root}/filtered_normalized_counts.h5ad\"\n",
        "\n",
        "# Check if the new patient's file exists\n",
        "if os.path.exists(new_patient_file):\n",
        "    # Load the h5ad file\n",
        "    new_patient_adata = ad.read_h5ad(new_patient_file)\n",
        "\n",
        "    print(f\"Adding data for patient {new_patient_id}...\")\n",
        "    new_patient_adata.obs['batch'] = new_patient_id  # Assign batch category for the current patient\n",
        "\n",
        "    combined_adata = combined_adata.concatenate(new_patient_adata, index_unique=None, batch_key='batch')\n",
        "\n",
        "    # Write the final combined dataset to disk\n",
        "    combined_adata.write(save_path)\n",
        "\n",
        "    print(\"Addition of the new patient's data finished.\")\n",
        "else:\n",
        "    print(f\"No data found for patient {new_patient_id}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9F6vk8lWp53i",
        "outputId": "b3a36d31-97cf-474d-b74c-b37a29d05daa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1830: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
            "  utils.warn_names_duplicates(\"obs\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding data for patient HRR339741...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1755: FutureWarning: The AnnData.concatenate method is deprecated in favour of the anndata.concat function. Please use anndata.concat instead.\n",
            "\n",
            "See the tutorial for concat at: https://anndata.readthedocs.io/en/latest/concatenation.html\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1830: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
            "  utils.warn_names_duplicates(\"obs\")\n",
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1830: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
            "  utils.warn_names_duplicates(\"obs\")\n",
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1830: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
            "  utils.warn_names_duplicates(\"obs\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Addition of the new patient's data finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I tried adding more patients to the combined data\n",
        "\n",
        "RAM crashed with these patients\n",
        "*   HRR339763 \n",
        "* HRR339743\n",
        "\n",
        "Patients Added:\n",
        "\n",
        "*   HRR339751\n",
        "*   HRR339757\n",
        "* HRR339741\n",
        "* HRR339748\n",
        "\n",
        "Patient HRR339754 has 4922 cells.\n",
        "Patient HRR339760 has 5193 cells.\n",
        "Patient HRR339763 has 7206 cells.\n",
        "Patient HRR339787 has 6195 cells.\n",
        "Patient HRR339790 has 5372 cells."
      ],
      "metadata": {
        "id": "N9nDt3aXsZHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths to the files\n",
        "folder_path = \"/content/drive/MyDrive/Pate_Lab/DNP/Bioinformatics/H17_LungMk/Data_files/HRA001149\"\n",
        "save_path = \"/content/drive/MyDrive/Pate_Lab/DNP/Bioinformatics/H17_LungMk/Combined_Data/combined_data.h5ad\"\n",
        "combined_data_path = \"/content/drive/MyDrive/Pate_Lab/DNP/Bioinformatics/H17_LungMk/Combined_Data/combined_data.h5ad\"\n",
        "\n",
        "# Load the combined data\n",
        "combined_adata = ad.read_h5ad(combined_data_path)\n",
        "\n",
        "# Add the new patient\n",
        "new_patient_id = \"HRR339748\"\n",
        "new_patient_root = f\"{folder_path}/{new_patient_id}\"\n",
        "new_patient_file = f\"{new_patient_root}/filtered_normalized_counts.h5ad\"\n",
        "\n",
        "# Check if the new patient's file exists\n",
        "if os.path.exists(new_patient_file):\n",
        "    # Load the h5ad file\n",
        "    new_patient_adata = ad.read_h5ad(new_patient_file)\n",
        "\n",
        "    print(f\"Adding data for patient {new_patient_id}...\")\n",
        "    new_patient_adata.obs['batch'] = new_patient_id  # Assign batch category for the current patient\n",
        "\n",
        "    combined_adata = combined_adata.concatenate(new_patient_adata, index_unique=None, batch_key='batch')\n",
        "\n",
        "    # Write the final combined dataset to disk\n",
        "    combined_adata.write(save_path)\n",
        "\n",
        "    print(\"Addition of the new patient's data finished.\")\n",
        "else:\n",
        "    print(f\"No data found for patient {new_patient_id}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQa9S8JFsYQi",
        "outputId": "038b6439-bcb5-4cd6-a124-c465c5cb67b2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1830: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
            "  utils.warn_names_duplicates(\"obs\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding data for patient HRR339748...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1755: FutureWarning: The AnnData.concatenate method is deprecated in favour of the anndata.concat function. Please use anndata.concat instead.\n",
            "\n",
            "See the tutorial for concat at: https://anndata.readthedocs.io/en/latest/concatenation.html\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1830: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
            "  utils.warn_names_duplicates(\"obs\")\n",
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1830: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
            "  utils.warn_names_duplicates(\"obs\")\n",
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1830: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
            "  utils.warn_names_duplicates(\"obs\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Addition of the new patient's data finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I tried adding more patients to the combined data\n",
        "\n",
        "RAM crashed with these patients\n",
        "*   HRR339763 \n",
        "* HRR339743\n",
        "* HRR339754\n",
        "* HRR339760\n",
        "* HRR339763\n",
        "* HRR339787\n",
        "* HRR339790\n",
        "\n",
        "Patients Added:\n",
        "\n",
        "*   HRR339751\n",
        "*   HRR339757\n",
        "* HRR339741\n",
        "* HRR339748"
      ],
      "metadata": {
        "id": "gIcFboL5uT8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths to the files\n",
        "folder_path = \"/content/drive/MyDrive/Pate_Lab/DNP/Bioinformatics/H17_LungMk/Data_files/HRA001149\"\n",
        "save_path = \"/content/drive/MyDrive/Pate_Lab/DNP/Bioinformatics/H17_LungMk/Combined_Data/combined_data.h5ad\"\n",
        "combined_data_path = \"/content/drive/MyDrive/Pate_Lab/DNP/Bioinformatics/H17_LungMk/Combined_Data/combined_data.h5ad\"\n",
        "\n",
        "# Load the combined data\n",
        "combined_adata = ad.read_h5ad(combined_data_path)\n",
        "\n",
        "# Add the new patient\n",
        "new_patient_id = \"HRR339790\"\n",
        "new_patient_root = f\"{folder_path}/{new_patient_id}\"\n",
        "new_patient_file = f\"{new_patient_root}/filtered_normalized_counts.h5ad\"\n",
        "\n",
        "# Check if the new patient's file exists\n",
        "if os.path.exists(new_patient_file):\n",
        "    # Load the h5ad file\n",
        "    new_patient_adata = ad.read_h5ad(new_patient_file)\n",
        "\n",
        "    print(f\"Adding data for patient {new_patient_id}...\")\n",
        "    new_patient_adata.obs['batch'] = new_patient_id  # Assign batch category for the current patient\n",
        "\n",
        "    combined_adata = combined_adata.concatenate(new_patient_adata, index_unique=None, batch_key='batch')\n",
        "\n",
        "    # Write the final combined dataset to disk\n",
        "    combined_adata.write(save_path)\n",
        "\n",
        "    print(\"Addition of the new patient's data finished.\")\n",
        "else:\n",
        "    print(f\"No data found for patient {new_patient_id}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HX68hLvYuOeo",
        "outputId": "6858dada-a618-4d82-c53a-d0959d74e1d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1830: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
            "  utils.warn_names_duplicates(\"obs\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding data for patient HRR339790...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1755: FutureWarning: The AnnData.concatenate method is deprecated in favour of the anndata.concat function. Please use anndata.concat instead.\n",
            "\n",
            "See the tutorial for concat at: https://anndata.readthedocs.io/en/latest/concatenation.html\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import anndata as ad\n",
        "\n",
        "# Identify all the patients\n",
        "combined_data_path = \"/content/drive/MyDrive/Pate_Lab/DNP/Bioinformatics/H17_LungMk/Combined_Data/combined_data.h5ad\"\n",
        "\n",
        "# Load the combined data\n",
        "combined_adata = ad.read_h5ad(combined_data_path)\n",
        "\n",
        "# Get patient IDs\n",
        "patient_ids = combined_adata.obs['batch'].unique()\n",
        "\n",
        "# Print patient IDs and cell counts\n",
        "for patient_id in patient_ids:\n",
        "    cell_count = sum(combined_adata.obs['batch'] == patient_id)\n",
        "    print(f'Patient ID: {patient_id}, Cell Count: {cell_count}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APM-ruQNv30C",
        "outputId": "5d379bc8-1077-410b-e2a3-51bc386000e2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patient ID: 0, Cell Count: 16194\n",
            "Patient ID: 1, Cell Count: 4847\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1830: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
            "  utils.warn_names_duplicates(\"obs\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scanpy as sc\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Path to the combined data file\n",
        "combined_data_path = \"/content/drive/MyDrive/Pate_Lab/DNP/Bioinformatics/H17_LungMk/Combined_Data/combined_data.h5ad\"\n",
        "\n",
        "# Load the combined data\n",
        "adata = sc.read_h5ad(combined_data_path)\n",
        "\n",
        "# Calculate n_genes, n_counts, percent_mito for each cell\n",
        "adata.obs['n_genes'] = adata.X.getnnz(axis=1)\n",
        "adata.obs['n_counts'] = adata.X.sum(axis=1).A1\n",
        "adata.var['mt'] = adata.var_names.str.startswith('MT-')  # assuming mitochondrial genes are prefixed with 'MT-'\n",
        "adata.obs['percent_mito'] = np.sum(\n",
        "    adata[:, adata.var['mt']].X, axis=1).A1 / np.sum(adata.X, axis=1).A1\n",
        "\n",
        "# Prepare a figure to plot the violin plots\n",
        "fig, axs = plt.subplots(3, 1, figsize=(5, 15))\n",
        "\n",
        "# A list of metrics to plot\n",
        "metrics = ['n_genes', 'n_counts', 'percent_mito']\n",
        "\n",
        "# Loop through each metric and plot a violin plot\n",
        "for ax, metric in zip(axs, metrics):\n",
        "    # Create a boxplot for each batch (patient)\n",
        "    sc.pl.violin(adata, metric, groupby='batch', ax=ax, show=False)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "265k7u3gxQIr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}